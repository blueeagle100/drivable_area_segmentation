{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore the Dice Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will briefly explore the Dice Loss and show how it's computed.\n",
    "\n",
    "The Dice Loss is derived from the [Dice-Sorensen Coefficient](https://en.wikipedia.org/wiki/S%C3%B8rensen%E2%80%93Dice_coefficient) relates the intersection of the predicted area and target area with the union of the predicted area and target area in a very similar manner to the [Intersection over Union (IoU)](https://en.wikipedia.org/wiki/Jaccard_index) loss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notation: \n",
    "- P: Predicted Area\n",
    "- T: Target Area\n",
    "- IoU: Intersection over Union\n",
    "- DSC: Dice-Sorensen Coeficient\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "    IoU = \\frac{|P \\cap T|}{|P \\cup T|}\n",
    "    \\\\ \\\\\n",
    "    DSC = \\frac{2 |P \\cap T|}{|P| + |T|}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Observing these definitions, we can see that scores for IoU and DSC range from $ 0 \\leq (IoU/DSC) \\leq 1 $, where 1 indicates a perfect score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have formally defined IoU and DSC, let's dive in and take a more intuitive look at what they do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# get image\n",
    "image = np.zeros((500, 500, 3), dtype=np.uint8) + 100\n",
    "\n",
    "tgt_pts = [[250, 100], [350, 250]]\n",
    "pred_pts = [[200, 125], [325, 275]]\n",
    "# intersect_pts = [[250, 125], [325, 250]]\n",
    "\n",
    "# Use opencv to add prediction and target areas\n",
    "# image = cv2.rectangle(image, tgt_pts[0], tgt_pts[1], (255, 255, 0), thickness=-1) # draw target\n",
    "# image = cv2.rectangle(image, pred_pts[0], pred_pts[1], (255, 0, 255), thickness=-1) # draw prediction\n",
    "# image = cv2.rectangle(image, overlap_pts[0], overlap_pts[1], (0, 255, 0), thickness=-1) # draw overlap\n",
    "\n",
    "# use numpy to slice the areas\n",
    "image[100:250, 250:350] = [255, 255, 0] # tgt\n",
    "image[125:275, 200:325] = [255, 0, 255] # prediction\n",
    "# image[125:250, 250:325] = [0, 255, 0] # intersection\n",
    "\n",
    "target = image[100:250, 250:350].copy()\n",
    "prediction = image[125:275, 200:325].copy()\n",
    "# intersection_ = image[125:250, 250:325].copy()\n",
    "\n",
    "# compute intersection\n",
    "y1 = max([tgt_pts[0][1], pred_pts[0][1]])\n",
    "y2 = max([tgt_pts[0][0], pred_pts[0][0]])\n",
    "\n",
    "x1 = min([tgt_pts[1][1], pred_pts[1][1]])\n",
    "x2 = min([tgt_pts[1][0], pred_pts[1][0]])\n",
    "\n",
    "image[y1:y2, x1:x2] = [0, 255, 0] # intersection\n",
    "intersection = image[y1:y2, x1:x2].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(5, 5))\n",
    "plt.imshow(image);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The area of intersection in green is also know as a True Positive (TP), the uncovered target in yellow is known as a False Negative (FN), the incorrect portion of the prediction in magenta is known as a False Positive (FP). If we add the following: \n",
    "$$ TP + FN + FP = |P \\cup T| = \\text{Union} $$\n",
    "\n",
    "We can also see that the TP is:\n",
    "$$ TP = |P \\cap T| = \\text{Intersection} $$\n",
    "\n",
    "We can now rewrite the IoU and DSC in terms of True Positive, False Negative, and False Positive:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "    IoU = \\frac{TP}{TP + FN + FP}\n",
    "    \\\\ \\\\\n",
    "    DSC = \\frac{2 \\cdot TP}{2 \\cdot TP + FN + FP}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "The denominator of the DSC comes from the fact that we just add the predicted with the target, this is analgous to the union of the predicted and target plus the intersection:\n",
    "    \n",
    "$$ |P \\cup T| + |P \\cap T| $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "Using this information we can compute the [Precision and Recall](https://en.wikipedia.org/wiki/Precision_and_recall#Precision) of our prediction.\n",
    "\n",
    "Notation:\n",
    "- TP: True Positive\n",
    "- FP: False Positive\n",
    "- FN: False Negative\n",
    "- TN: True Negative\n",
    "$$\n",
    "\\begin{align*}\n",
    "    \\text{Precision} &= \\frac{TP}{TP + FP}\n",
    "    \\\\ \\\\\n",
    "    \\text{Recall} &= \\frac{TP}{TP + FN}\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "I use the following mnemonic to help remeber what Precision and Recall actually stand for:\n",
    "- \"Positive Precision\" --> Precision is the ratio of True Positive to True and False Positives\n",
    "- \"Real Recall\" &emsp; &ensp; &ensp;  --> Recall is the ratio of True Positives to the (combined) number of target values\n",
    "<br>\n",
    "$$ |\\text{Target Values}| = |TP + FN| $$\n",
    "\n",
    "This isnt a perfect mnemonic, but it is helpful when starting to use Precision and Recall\n",
    "\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How do Precision and Recall relate to the Dice Coefficient?\n",
    "\n",
    "The Dice-Sorenson Coefficient is actually the [F1-Score](https://en.wikipedia.org/wiki/F-score). The F1 score is the harmonic mean of the Precision and Recall, which means that it provides a measure for both the precision and the recall.\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "    F1 = \\frac{2}{\\frac{1}{\\text{Precision}} + \\frac{1}{\\text{Recall}}} = \\frac{2 \\cdot TP}{2 \\cdot TP + FN + FP} = DSC\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "The derivation is shown in the appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How do we compute the Dice Loss?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compute the Dice Coefficient as:\n",
    "\n",
    "$$ \n",
    "\\begin{align}\n",
    "    DSC = \\frac{2 * \\sum_j |P \\cap T|_j }{\\sum_i |P_i| + |T_i| + \\epsilon} , \\qquad \\epsilon > 0\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Where $ \\epsilon $ prevents division by 0\n",
    "\n",
    "Remember: $ 0 \\leq DSC \\leq 1 $, where 1 indicates a perfect score. Most optimizers are equipped for minimization, so we would like to have 0 equal to the perfect score. To do this we simply subtract the DSC from 1:\n",
    "\n",
    "$$ \n",
    "\\begin{align}\n",
    "    \\text{Dice Loss} = 1 - DSC \n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.1422, 0.1093, 0.5076, 0.6641, 0.6876],\n",
      "          [0.0994, 0.0593, 0.6191, 0.4130, 0.3638],\n",
      "          [0.5187, 0.2465, 0.3413, 0.3857, 0.1046]],\n",
      "\n",
      "         [[0.7981, 0.5505, 0.2023, 0.2478, 0.1289],\n",
      "          [0.1771, 0.1676, 0.2888, 0.3531, 0.3765],\n",
      "          [0.2417, 0.0702, 0.4224, 0.3205, 0.0742]],\n",
      "\n",
      "         [[0.0597, 0.3402, 0.2901, 0.0881, 0.1834],\n",
      "          [0.7235, 0.7730, 0.0922, 0.2340, 0.2597],\n",
      "          [0.2396, 0.6834, 0.2363, 0.2938, 0.8212]]]])\n",
      "tensor([[[1, 1, 0, 0, 0],\n",
      "         [2, 2, 0, 0, 1],\n",
      "         [0, 2, 1, 0, 2]]])\n",
      "tensor([[[0, 2, 0, 0, 2],\n",
      "         [0, 2, 0, 2, 0],\n",
      "         [1, 2, 0, 1, 2]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "N = 3 # number of classes\n",
    "outputs = torch.randn(1, N, 3, 5)\n",
    "output_soft = torch.softmax(outputs, dim=1)\n",
    "predictions = torch.argmax(output_soft, dim=1)\n",
    "\n",
    "targets = torch.empty(1, 3, 5, dtype=torch.long).random_(N)\n",
    "\n",
    "print(output_soft)\n",
    "print(predictions)\n",
    "print(targets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encode the targets\n",
    "targets_one_hot = torch.zeros_like(output_soft)\n",
    "for i in range(N):\n",
    "    targets_one_hot[0, i, targets.squeeze(0) == i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1., 0., 1., 1., 0.],\n",
       "          [1., 0., 1., 0., 1.],\n",
       "          [0., 0., 1., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0.],\n",
       "          [1., 0., 0., 1., 0.]],\n",
       "\n",
       "         [[0., 1., 0., 0., 1.],\n",
       "          [0., 1., 0., 1., 0.],\n",
       "          [0., 1., 0., 0., 1.]]]])"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([6.3349])\n",
      "tensor([30.])\n"
     ]
    }
   ],
   "source": [
    "intersection = torch.sum(output_soft * targets_one_hot, dim=(1, 2, 3))\n",
    "cardinality = torch.sum(output_soft + targets_one_hot, dim=(1, 2, 3))\n",
    "\n",
    "print(intersection)\n",
    "print(cardinality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5777])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eps = 1e-6\n",
    "dice_loss = 1 - (2 * intersection / (cardinality + eps))\n",
    "dice_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_loss(outputs, targets):\n",
    "    eps = 1e-6\n",
    "\n",
    "    output_soft = torch.softmax(outputs, dim=1)\n",
    "    predictions = torch.argmax(output_soft, dim=1)\n",
    "\n",
    "    # one hot encode the targets\n",
    "    targets_one_hot = torch.zeros_like(output_soft)\n",
    "    for i in range(N):\n",
    "        targets_one_hot[0, i, targets.squeeze(0) == i] = 1\n",
    "\n",
    "    \n",
    "    intersection = torch.sum(output_soft * targets_one_hot, dim=(1, 2, 3))\n",
    "    cardinality = torch.sum(output_soft + targets_one_hot, dim=(1, 2, 3))\n",
    "\n",
    "    dice_loss = 1 - (2 * intersection / (cardinality + eps))\n",
    "\n",
    "    return dice_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5777)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchgeometry as tgm\n",
    "tgm.losses.DiceLoss()(outputs, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8609, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "N = 5 # number of classes\n",
    "predictions = torch.randn(1, N, 3, 5, requires_grad=True)\n",
    "targets = torch.empty(1, 3, 5, dtype=torch.long).random_(N)\n",
    "\n",
    "tgm.losses.DiceLoss()(predictions, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix\n",
    "\n",
    "Relate the F1-score to the Dice-Sorenson Coefficient\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "    F1 &= \\frac{2}{\\frac{\\text{Recall}}{\\text{Precision} \\cdot \\text{Recall}} + \\frac{\\text{Precision}}{\\text{Precision} \\cdot \\text{Recall}}}\n",
    "\\\\\n",
    "\\\\\n",
    "&= 2 \\frac{(\\text{Precision} \\cdot \\text{Recall})}{\\text{Precision} + \\text{Recall}}\n",
    "\\\\\n",
    "\\\\\n",
    "&= 2 \\frac{\\frac{TP}{TP + FP} \\cdot \\frac{TP}{TP + FN}}{\\frac{TP}{TP + FP} + \\frac{TP}{TP + FN}}\n",
    "\\\\\n",
    "\\\\\n",
    "&= 2 \\frac{\\frac{TP}{(TP + FP) \\cdot (TP + FN)}}{\\frac{1}{TP + FP} + \\frac{1}{TP + FN}}\n",
    "\\\\\n",
    "\\\\\n",
    "&= 2 \\frac{\\frac{TP}{(TP + FP) \\cdot (TP + FN)}}{\\frac{(TP + FN) + (TP + FP)}{(TP + FP) \\cdot (TP + FN)}}\n",
    "\\\\\n",
    "\\\\\n",
    "&= 2 \\frac{TP}{(TP + FN) + (TP + FP)}\n",
    "\\\\\n",
    "\\\\\n",
    "&= \\frac{2 \\cdot TP}{2 \\cdot TP + FN + FP}\n",
    "\\end{align*}\n",
    "$$\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6c3515861ec4313dacaa20b0eec5bf326e6557b6589b7b6a4fe3c8baa566747d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
